{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pop & Housing variables pulled from 2010, and 2020 Censuses (using Cen API) for urban villages,  City of Phoenix and U.S.\n",
    "### added Maricopa County, State of Arizona, and comparable cities\n",
    "\n",
    "Total Housing Units, Population, Population by Ethncity, Total Occupied Housing Units,  \n",
    "\n",
    "Note: to update list of comp cities, adjust dictionary in getters script. also note Indianapolis is a consolidated city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getters as get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import block group data\n",
    "bgp_10 = pd.read_csv('../data/geo/bgp_vil_10.csv')\n",
    "bgp_20 = pd.read_csv('../data/geo/bgp_vil_20.csv')\n",
    "for df in [bgp_10,bgp_20]: df.geoid = df.geoid.apply(lambda x: '{0:0>12}'.format(x))\n",
    "    \n",
    "drop_cols = ['aland','awater','lat','lon','land_acre']\n",
    "for df in [bgp_10,bgp_20]: df.drop(drop_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import block data\n",
    "blk_10 = pd.read_csv('../data/geo/blk_vil_10_reduced.csv')\n",
    "blk_20 = pd.read_csv('../data/geo/blk_vil_20_reduced.csv')\n",
    "for df in [blk_10,blk_20]: df.geoid = df.geoid.apply(lambda x: '{0:0>15}'.format(x))\n",
    "\n",
    "for df in [blk_10,blk_20]: df.drop(drop_cols,axis=1,inplace=True)\n",
    "for df in [blk_10,blk_20]: df.rename({'geoid':'GEO_ID'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set sources, define variable lists by Decennial Census year\n",
    "#SF1 Dec in 2010, Redistricting file in 2020 (until 2020 tables are released)\n",
    "\n",
    "source_dec = 'dec/sf1'\n",
    "source_red = 'dec/pl'\n",
    "\n",
    "#variables for each Census\n",
    "years = {'2010':'P001001,P005003,P005004,P005005,P005006,P005007,P005008,P005009,P005010,H003001,H003002,H003003',\\\n",
    "        '2020':'P1_001N,P2_002N,P2_005N,P2_006N,P2_007N,P2_008N,P2_009N,P2_010N,P2_011N,H1_001N,H1_002N,H1_003N'}\n",
    "\n",
    "#rename 2010 columns to group\n",
    "col_10_rename={'P001001':'Pop_10E','P005003':'P_Wh_10E','P005004':'P_Bl_10E','P005006':'P_As_10E','P005010':'P_Hi_10E',\\\n",
    "               'P005005':'P_Ot_10E','P005007':'P_Ot_10E','P005008':'P_Ot_10E','P005009':'P_Ot_10E',\\\n",
    "              'H003001':'Hou_10E','H003002':'Hou_O_10E','H003003':'Hou_V_10E'}\n",
    "\n",
    "#rename 2020 columns to group\n",
    "col_20_rename = {'P1_001N':'Pop_20E','P2_002N':'P_Hi_20E',\\\n",
    "              'P2_005N':'P_Wh_20E','P2_006N':'P_Bl_20E',\\\n",
    "              'P2_007N':'P_Ot_20E','P2_008N':'P_As_20E','P2_009N':'P_Ot_20E',\\\n",
    "              'P2_010N':'P_Ot_20E','P2_011N':'P_Ot_20E','H1_001N':'Hou_20E',\\\n",
    "              'H1_002N':'Hou_O_20E','H1_003N':'Hou_V_20E'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urban Village for 2010 and 2020 from block groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df10 = get.get_bgp(source_dec,list(years.keys())[0],years.get(list(years.keys())[0]))\n",
    "df20 = get.get_bgp(source_red,list(years.keys())[1],years.get(list(years.keys())[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uvil(geodf,df,rename_col):\n",
    "    df.rename(columns=rename_col,inplace=True)\n",
    "    for col in df.columns[:-1]: df[col] = df[col].astype(int)\n",
    "    df = pd.merge(geodf,df,how='left',left_on='geoid',right_on='GEO_ID')\n",
    "    df = df.drop(['GEO_ID','geoid'],axis=1)\n",
    "    df = df.groupby(df.columns,axis=1).sum().groupby('name').sum().reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "u10 = make_uvil(bgp_10,df10,col_10_rename)\n",
    "u20 = make_uvil(bgp_20,df20,col_20_rename)\n",
    "uvil_bg = pd.merge(u10,u20,how='left',on='name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urban Village for 2010 and 2020 from blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk10 = get.get_blk(source_dec,list(years.keys())[0],years.get(list(years.keys())[0]),blk_10)\n",
    "bk20 = get.get_blk(source_red,list(years.keys())[1],years.get(list(years.keys())[1]),blk_20)\n",
    "\n",
    "for df in [bk10,bk20]:\n",
    "    for col in df.columns[2:]:\n",
    "        df[col] = df[col].astype(int)\n",
    "    df.drop(['GEO_ID'],axis=1,inplace=True)\n",
    "    \n",
    "bk10.rename(columns=col_10_rename,inplace=True)\n",
    "bk20.rename(columns=col_20_rename,inplace=True)\n",
    "\n",
    "bk10 = bk10.groupby(bk10.columns,axis=1).sum().groupby(['name']).sum().reset_index()\n",
    "bk20 = bk20.groupby(bk20.columns,axis=1).sum().groupby(['name']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvil_bk = pd.merge(bk10,bk20,how='left',on='name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Table function for all other geos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(df,rename):\n",
    "    df.rename(columns=rename,inplace=True)\n",
    "    for col in df.columns[:-1]: df[col] = df[col].astype(int)\n",
    "    df = df.groupby(df.columns,axis=1).sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U.S. for 2010 and 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "us10 = get.get_us(source_dec,list(years.keys())[0],years.get(list(years.keys())[0]))\n",
    "us20 = get.get_us(source_red,list(years.keys())[1],years.get(list(years.keys())[1]))\n",
    "us10 = make_table(us10,col_10_rename)\n",
    "us20 = make_table(us20,col_20_rename)\n",
    "us = pd.merge(us10,us20,how='left',on='us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "us.rename(columns={'us':'name'},inplace=True)\n",
    "us = us[['name']+[col for col in us.columns if col !='name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maricopa County for 2010 and 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar10 = get.get_maricopa(source_dec,list(years.keys())[0],years.get(list(years.keys())[0]))\n",
    "mar20 = get.get_maricopa(source_red,list(years.keys())[1],years.get(list(years.keys())[1]))\n",
    "mar10 = make_table(mar10,col_10_rename)\n",
    "mar20 = make_table(mar20,col_20_rename)\n",
    "mar = pd.merge(mar10,mar20,how='left',on='GEO_ID')\n",
    "mar.rename(columns={'GEO_ID':'name'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arizona for 2010 and 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "az10 = get.get_az(source_dec,list(years.keys())[0],years.get(list(years.keys())[0]))\n",
    "az20 = get.get_az(source_red,list(years.keys())[1],years.get(list(years.keys())[1]))\n",
    "az10 = make_table(az10,col_10_rename)\n",
    "az20 = make_table(az20,col_20_rename)\n",
    "az = pd.merge(az10,az20,how='left',on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.rename(columns={'state':'name'},inplace=True)\n",
    "az = az[['name']+[col for col in az.columns if col !='name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maricopa Places for 2010 and 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plc10 = get.get_az_plc(source_dec,list(years.keys())[0],years.get(list(years.keys())[0]))\n",
    "plc20 = get.get_az_plc(source_red,list(years.keys())[1],years.get(list(years.keys())[1]))\n",
    "plc10 = make_table(plc10,col_10_rename)\n",
    "plc20 = make_table(plc20,col_20_rename)\n",
    "plc = pd.merge(plc10,plc20,how='left',on='GEO_ID')\n",
    "plc.rename(columns={'GEO_ID':'name'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comp cities for 2010 and 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps10 = get.get_comp_cities(source_dec,list(years.keys())[0],years.get(list(years.keys())[0]))\n",
    "comps20 = get.get_comp_cities(source_red,list(years.keys())[1],years.get(list(years.keys())[1]))\n",
    "comps10 = make_table(comps10,col_10_rename)\n",
    "comps20 = make_table(comps20,col_20_rename)\n",
    "comps = pd.merge(comps10,comps20,how='left',on='GEO_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps.rename(columns={'GEO_ID':'name'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat all geos together & export to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {'1':'US','4':'AZ','4013':'Maricopa',\\\n",
    "         '4865000':'San Antonio','4835000':'Houston','1235000':'Jacksonville',\\\n",
    "         '1836000':'Indianapolis','477000':'Tucson','3502000':'Albuquerque'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([us,mar,az,comps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.name = final.name.astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['name'] = final['name'].map(rename)\n",
    "uvil_bg['name'] = uvil_bg.name +'_bg'\n",
    "final = pd.concat([uvil_bk,final,plc,uvil_bg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('output/dec_pop_hou_race.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
